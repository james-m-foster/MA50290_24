{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "727f79e4",
   "metadata": {},
   "source": [
    "# Problem Sheet 9\n",
    "\n",
    "## Perceptron algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ae91d0",
   "metadata": {},
   "source": [
    "## Task (a):\n",
    "Consider the dataset $\\mathbf{D} = \\{(\\mathbf{x}_1,y_1), (\\mathbf{x}_2,y_2)\\}$ from Problem Sheet 6, where\n",
    "$$\n",
    "\\mathbf{x}_1 = \\begin{bmatrix}-1 \\\\ 1\\end{bmatrix}, \\qquad \\mathbf{x}_2 = \\begin{bmatrix}2 \\\\ -1\\end{bmatrix},\n",
    "$$\n",
    "and $y_1=1$, $y_2=-1$.\n",
    "\n",
    "- Calculate iterations $\\boldsymbol\\theta_0\\ldots,\\boldsymbol\\theta_k$ of the Perceptron algorithm until convergence ($y_i \\langle \\boldsymbol\\theta_k, \\mathbf{x}_i\\rangle >0$ for both $i=1$ and $2$) for two choices of $i_0$ in the first step:\n",
    "  - when $i_0=1$ is selected;\n",
    "  - when $i_0=2$ is selected.\n",
    "- Which of these two scenarios produces $\\boldsymbol\\theta_k$ collinear to the Support Vector Machine solution $\\boldsymbol\\theta^* = (-1/2,1/2)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e0481e",
   "metadata": {},
   "source": [
    "## Solution:\n",
    "\n",
    "Note that $\\boldsymbol\\theta_0=\\mathbf{0}$, so in general any $i_0=1,\\ldots,m$ can be chosen.\n",
    "- $i_0=1$:\n",
    "$$\n",
    "\\boldsymbol\\theta_1 = y_1 \\mathbf{x}_1 = \\begin{bmatrix}-1 \\\\ 1\\end{bmatrix},\n",
    "$$\n",
    "now $y_2 \\langle \\boldsymbol\\theta_1, \\mathbf{x}_2 \\rangle = - (-2 - 1) = 3 > 0$, and the algorithm stops.\n",
    "- $i_0=2$:\n",
    "$$\n",
    "\\boldsymbol\\theta_1 = y_2 \\mathbf{x}_2 = \\begin{bmatrix}-2 \\\\ 1\\end{bmatrix},\n",
    "$$\n",
    "and $y_1 \\langle \\boldsymbol\\theta_1, \\mathbf{x}_1 \\rangle = 2 + 1 = 3 > 0$, and the algorithm stops.\n",
    "\n",
    "However, note that only $i_0=1$ gives $\\boldsymbol\\theta_1 = 2 \\boldsymbol\\theta^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0163f37c",
   "metadata": {},
   "source": [
    "## Task (b) (Warm-up):\n",
    "\n",
    "- Suggest a method to choose $i_k$ that gives the fastest estimated convergence of the Perceptron algorithm, that is, the largest practically computable lower bound of $\\cos \\angle (\\boldsymbol\\theta^*,\\boldsymbol\\theta_{k+1})$ in Theorem 4.38."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30e0f2e",
   "metadata": {},
   "source": [
    "## Solution:\n",
    "\n",
    "$\\cos \\angle (\\boldsymbol\\theta^*,\\boldsymbol\\theta_{k+1})$ depends on the ratio of two terms which in turn depends in $i_k$: $\\langle \\boldsymbol\\theta^*, \\boldsymbol\\theta_{k+1} \\rangle = \\langle \\boldsymbol\\theta^*, \\boldsymbol\\theta_{k} \\rangle + y_{i_k} \\langle \\boldsymbol\\theta^*, \\mathbf{x}_{i_k} \\rangle$, which we cannot control though since we don't know $\\boldsymbol\\theta^*$, and $\\|\\boldsymbol\\theta_{k+1}\\|_2^2 = \\|\\boldsymbol\\theta_k\\|_2^2 + 2 y_{i_k} \\langle \\boldsymbol\\theta_k, \\mathbf{x}_{i_k} \\rangle + \\|\\mathbf{x}_{i_k}\\|_2^2$. So we obtain\n",
    "$$\n",
    "\\cos \\angle (\\boldsymbol\\theta^*,\\boldsymbol\\theta_{k+1}) = \\frac{\\langle \\boldsymbol\\theta^*, \\boldsymbol\\theta_{k} \\rangle + y_{i_k} \\langle \\boldsymbol\\theta^*, \\mathbf{x}_{i_k} \\rangle}{B \\|\\boldsymbol\\theta_{k+1}\\|_2} \\ge \\frac{\\langle \\boldsymbol\\theta^*, \\boldsymbol\\theta_{k} \\rangle + 1}{B \\|\\boldsymbol\\theta_{k+1}\\|_2},\n",
    "$$\n",
    "and to maximize the lower bound in the right hand side we need to minimize $\\|\\boldsymbol\\theta_{k+1}\\|_2$ over $i_k: i_k=1,\\ldots,m$, $y_{i_k} \\langle \\boldsymbol\\theta_k, \\mathbf{x}_{i_k}\\rangle \\le 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619b52bc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bdc8a7",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "- Write a Python function `PerceptronM(X,y, K=100)` for the modified Perceptron algorithm designed in Task (b), with the same inputs `X`, `y` and `K` as in the original `Perceptron` function in the `Perceptron.ipynb` notebook. You can also test your function on the same example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbe98ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution:\n",
    "import numpy as np\n",
    "\n",
    "def PerceptronM(X,y, K=100):\n",
    "    theta = np.zeros(X.shape[1])\n",
    "    for k in range(K):\n",
    "        best_norm = np.inf\n",
    "        best_theta = theta\n",
    "        for i in range(y.size):\n",
    "            if y[i] * X[i] @ theta <= 0:\n",
    "                theta_next = theta + y[i] * X[i]\n",
    "                if np.linalg.norm(theta_next) < best_norm:\n",
    "                    best_norm = np.linalg.norm(theta_next)\n",
    "                    best_theta = theta_next\n",
    "        theta = best_theta\n",
    "        if best_norm == np.inf:\n",
    "            break\n",
    "        print(f\"iteration {k}\")\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f115c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "theta: [ 0.  0.  2.  0. -1.  1.]\n",
      "predicted labels: [ 1. -1.  1. -1.  1. -1.]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "# Spam term-to-document dataset, X = {x_1,...,x_m}, with terms:\n",
    "#               AND OFFER THE  OF SALE\n",
    "Xh = np.array([[ 1 ,  1 ,  0 , 1 , 1],   # x_1   spam\n",
    "               [ 0 ,  0 ,  1 , 1 , 0],   # x_2   not spam\n",
    "               [ 0 ,  1 ,  1 , 0 , 0],   # x_3   spam\n",
    "               [ 1 ,  0 ,  0 , 1 , 0],   # x_4   not spam\n",
    "               [ 1 ,  0 ,  1 , 0 , 1],   # x_5   spam\n",
    "               [ 1 ,  0 ,  1 , 1 , 0]    # x_6   not spam\n",
    "             ])\n",
    "y = np.array([1,-1,1,-1,1,-1])\n",
    "X = np.hstack((np.ones((Xh.shape[0],1)), Xh)) # Affine -> Homogeneous form\n",
    "\n",
    "theta = PerceptronM(X[:4], y[:4])\n",
    "print(\"theta: \" + str(theta))\n",
    "print(\"predicted labels: \" + str(np.sign(X @ theta)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
